{"cells":[{"cell_type":"markdown","metadata":{"id":"zu-6tWSj9xqQ"},"source":["# **Model 1**"]},{"cell_type":"markdown","metadata":{"id":"qvTlKYFN-M1c"},"source":["## 1. Python packages and custom functions"]},{"cell_type":"markdown","source":["### 1.1 Python packages"],"metadata":{"id":"cma8U1MrKC6-"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"vsHEsn2e_O8-","executionInfo":{"status":"ok","timestamp":1718981474018,"user_tz":-120,"elapsed":150625,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["%%capture\n","!pip install dcase_util\n","!pip install pytorch-ignite\n","!pip install torch_audiomentations\n","!pip install colorednoise\n","!pip install timm"]},{"cell_type":"code","source":["# Required functions/packages:\n","\n","# General:\n","import numpy as np\n","import os\n","import ntpath\n","import random\n","import json\n","import pandas as pd\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","from tqdm import tqdm\n","from glob import glob\n","import dcase_util\n","\n","# PyTorch:\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchaudio\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch_audiomentations import ApplyImpulseResponse\n","import colorednoise as cn\n","from timm import create_model, list_models\n","\n","# Ignite Framework:\n","from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n","from ignite.metrics import Accuracy, Loss, MetricsLambda, Metric\n","from ignite.handlers import ModelCheckpoint, EarlyStopping\n","from ignite._utils import convert_tensor\n","\n","# Ignore warnings:\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Determinism Settings (comment out for a non-deterministic run):\n","seed = 1000\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"],"metadata":{"id":"PwEAa8vMXwGW","executionInfo":{"status":"ok","timestamp":1718981585502,"user_tz":-120,"elapsed":317,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dASIioVx6qGD"},"source":["### 1.2 Custom functions"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"a4YOR99H6oWW","executionInfo":{"status":"ok","timestamp":1718981496426,"user_tz":-120,"elapsed":32,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class Compose:\n","    def __init__(self, transforms: list):\n","        \"\"\"\n","        Base class to chain data augmentation methods.\n","\n","        Based and modified from\n","        https://github.com/albumentations-team/albumentations/blob/master/albumentations/core/composition.py\n","        and\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        transforms: list of augmentation methods, e.g. [NoiseInjection(), GaussianNoise()]\n","        \"\"\"\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        for trns in self.transforms:\n","            y = trns(y, sr)\n","        return y"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TLj2D_8O7Cky","executionInfo":{"status":"ok","timestamp":1718981496426,"user_tz":-120,"elapsed":30,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class AudioTransform:\n","    def __init__(self, always_apply=False, p=0.5):\n","        \"\"\"\n","        Base class for data augmentations on waveforms or spectrogram's.\n","\n","        Based and modified from\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        always_apply: bool. Can be turned to True for debugging purposes.\n","        p: float between 0-1. Probability to apply the augmentation.\n","        \"\"\"\n","        self.always_apply = always_apply\n","        self.p = p\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        if self.always_apply:\n","            return self.apply(y, sr=sr)\n","        else:\n","            if np.random.rand() < self.p:\n","                return self.apply(y, sr=sr)\n","            else:\n","                return y\n","\n","    def apply(self, y: np.ndarray, **params):\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fhl81-4K6gUl","executionInfo":{"status":"ok","timestamp":1718981496871,"user_tz":-120,"elapsed":475,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class PinkNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n","        \"\"\"\n","        Pink noise augmentation to be applied on waveforms.\n","\n","        Based and modified from\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        always_apply: bool. Can be turned to True for debugging purposes.\n","        p: float between 0-1. Probability to apply the augmentation.\n","        min_snr: int. Minimum signal-to-noise ratio.\n","        max_snr: int. Maximum signal-to-noise ratio.\n","        \"\"\"\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = torch.distributions.Uniform(self.min_snr, self.max_snr).sample([1])\n","        a_signal = torch.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        pink_noise = torch.from_numpy(cn.powerlaw_psd_gaussian(1, len(y)))\n","        a_pink = torch.sqrt(pink_noise ** 2).max()\n","        augmented = y + (pink_noise * 1 / a_pink * a_noise).type(y.dtype)\n","        return augmented"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZtEgEQE76fy8","executionInfo":{"status":"ok","timestamp":1718981496872,"user_tz":-120,"elapsed":12,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class GaussianNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n","        \"\"\"\n","        Gaussian noise augmentation to be applied on waveforms.\n","\n","        Based and modified from\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        always_apply: bool. Can be turned to True for debugging purposes.\n","        p: float between 0-1. Probability to apply the augmentation.\n","        min_snr: int. Minimum signal-to-noise ratio.\n","        max_snr: int. Maximum signal-to-noise ratio.\n","        \"\"\"\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = torch.distributions.Uniform(self.min_snr, self.max_snr).sample([1])\n","        a_signal = torch.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        white_noise = torch.randn(len(y))\n","        a_white = torch.sqrt(white_noise ** 2).max()\n","        augmented = y + white_noise * 1 / a_white * a_noise\n","        return augmented"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TTsL4ZLY6Nh5","executionInfo":{"status":"ok","timestamp":1718981496872,"user_tz":-120,"elapsed":11,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class OneOf(Compose):\n","    def __init__(self, transforms, p=0.5):\n","        \"\"\"\n","        Chooses one transformation/augmentation method from a provided\n","        list with probability p.\n","\n","        Based and modified from\n","        https://github.com/albumentations-team/albumentations/blob/master/albumentations/core/composition.py\n","        and\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        transforms: list of augmentation methods, e.g. [NoiseInjection(), GaussianNoise()].\n","        p: float. Probability to apply augmentation.\n","        \"\"\"\n","        super().__init__(transforms)\n","        self.p = p\n","        transforms_ps = [t.p for t in transforms]\n","        s = sum(transforms_ps)\n","        self.transforms_ps = [t / s for t in transforms_ps]\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        data = y\n","        if self.transforms_ps and (random.random() < self.p):\n","            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n","            t = random_state.choice(self.transforms, p=self.transforms_ps)\n","            data = t(y, sr)\n","        return data"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Og-D_QgI6Vno","executionInfo":{"status":"ok","timestamp":1718981496872,"user_tz":-120,"elapsed":10,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"outputs":[],"source":["class NoiseInjection(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5):\n","        \"\"\"\n","        Noise injection augmentation to be applied on waveforms.\n","\n","        Based and modified from\n","        https://github.com/tattaka/birdclef-2021/blob/7fed19356f8e4cc499ed29dbcdd7b8e960de6cef/src/stage1/main.py\n","        under MIT license.\n","\n","        Parameters\n","        ----------\n","        always_apply: bool. Can be turned to True for debugging purposes.\n","        p: float between 0-1. Probability to apply the augmentation.\n","        max_noise_level: float. Maximum noise level of the injection.\n","        \"\"\"\n","        super().__init__(always_apply, p)\n","\n","        self.noise_level = (0.0, max_noise_level)\n","\n","    def apply(self, y: np.ndarray, **params):\n","        noise_level = torch.distributions.Uniform(*self.noise_level).sample([1])\n","\n","        noise = torch.randn(len(y))\n","        augmented = y + noise * noise_level\n","        return augmented"]},{"cell_type":"code","source":["class F1Score(Metric):\n","\n","    def __init__(self, *args, **kwargs):\n","        self.f1 = 0\n","        self.count = 0\n","        super().__init__(*args, **kwargs)\n","\n","    def update(self, output):\n","        y_pred, y = output[0].detach(), output[1].detach()\n","\n","        _, predicted = torch.max(y_pred, 1)\n","        f = f1_score(y.cpu(), predicted.cpu(), average='macro', zero_division=1)\n","        self.f1 += f\n","        self.count += 1\n","\n","    def reset(self):\n","        self.f1 = 0\n","        self.count = 0\n","        super(F1Score, self).reset()\n","\n","    def compute(self):\n","        return self.f1 / self.count"],"metadata":{"id":"wcRu0n_hZcvi","executionInfo":{"status":"ok","timestamp":1718981496873,"user_tz":-120,"elapsed":10,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def classifier_calculator(n_bins=None, sub_spectrogram_size=None, hop_size=None):\n","  n_classifiers = 0\n","  bins_per_sub = []\n","  size = sub_spectrogram_size\n","  start = 0\n","  while(hop_size*n_classifiers <= n_bins - sub_spectrogram_size):\n","    n_classifiers = n_classifiers + 1\n","    bins_per_sub.append([start,size])\n","    start += hop_size\n","    size += hop_size\n","\n","  # + 1 for global classifier:\n","  n_classifiers = n_classifiers + 1\n","  bins_per_sub.append(['GLOBAL'])\n","  print('Total number of classifiers (global included) =', n_classifiers)\n","\n","  # Sub-spectrogram bin range:\n","  print(bins_per_sub)\n","\n","  return n_classifiers"],"metadata":{"id":"wVpRhcZV7Z2o","executionInfo":{"status":"ok","timestamp":1718981496873,"user_tz":-120,"elapsed":10,"user":{"displayName":"Daan Mulckhuyse","userId":"18102877053212470272"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Q-JvnFR9o2n"},"source":["## 2. Loading and transforming data"]},{"cell_type":"code","source":["\"\"\"\n","This script contains the basic building blocks of the DataLoader and Transforms for preprocessing the data in batches.\n","\n","Updated February 2019\n","Sai Samarth R Phaye\n","\"\"\"\n","\n","class ToTensor(object):\n","\t\"\"\" Convert ndarrays in sample to Tensors.\"\"\"\n","\n","\tdef __call__(self, sample):\n","\t\tdata, label = sample['data'], sample['label']\n","\n","\t\t# swap color axis (not required)\n","\t\tdata = data.transpose((0, 1, 2, 3))\n","\n","\t\treturn {'data': torch.from_numpy(data),\n","\t\t\t\t'label': torch.from_numpy(label)}"],"metadata":{"id":"EL_vk7fSSmuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmNZVqdyKfqE"},"outputs":[],"source":["\n","class ToSubSpectrograms(object):\n","\t\"\"\" Generate Sub-Spectrogram Tensors \"\"\"\n","\tdef __init__(self, sub_spectrogram_size=None, hop_size=None, n_bins=None):\n","\t\t\"\"\"\n","\t\tParameters\n","\t\t----------\n","\t\tsub_spectrogram_size : int\n","\t\t\tSize of the SubSpectrogram. Default: 20\n","\n","\t\thop_size : int\n","\t\t\tMel-bin hop size of the SubSpectrogram. Default 10\n","\n","\t\tn_bins : int\n","\t\t\tNumber of mel-bins of the Spectrogram extracted. Default: 40.\n","\t\t\"\"\"\n","\t\tself.sub_spectrogram_size, self.hop_size, self.n_bins = sub_spectrogram_size, hop_size, n_bins\n","\n","\tdef __call__(self, sample):\n","\t\t\"\"\"\n","\t\tParameters\n","\t\t----------\n","\t\tsample : PyTorch tensor\n","\t\t\tThe input tensor data and label\n","\t\tReturns\n","\t\t-------\n","\t\tsub_spectrograms: tensor\n","\t\t\tA list of sub-spectrograms. Default size [channels, sub_spectrogram_size, time_indices, n_sub_spectrograms]\n","\t\tlabel: tensor\n","\t\t\tCorresponding label\n","\t\t\"\"\"\n","\t\tspectrogram, label = sample['data'], sample['label']\n","\n","\t\ti = 0\n","\t\tsub_spectrograms = torch.from_numpy(np.asarray([]))\n","\t\twhile(self.hop_size*i <= self.n_bins - self.sub_spectrogram_size):\n","\n","\t\t\t# Extract a Sub-Spectrogram\n","\t\t\tsubspectrogram = spectrogram[:,i*self.hop_size:i*self.hop_size+self.sub_spectrogram_size,:, :]\n","\n","\t\t\tif i == 0:\n","\t\t\t\tsub_spectrograms = subspectrogram\n","\t\t\telse:\n","\t\t\t\tsub_spectrograms = torch.cat((subspectrogram, sub_spectrograms), 3)\n","\n","\t\t\ti = i + 1\n","\n","\t\treturn sub_spectrograms, label\n"]},{"cell_type":"code","source":["class InsectDataset(Dataset):\n","\n","\tdef __init__(self,\n","\t            data_dir=None,\n","\t\t\t\t\t\t\troot_dir=None,\n","\t\t\t\t\t\t\tdefault_labels_path=None,\n","\t\t\t\t\t\t\tn_bins=None,\n","\t\t\t\t\t\t\thop_length=None,\n","\t\t\t\t\t\t\ttop_db=None,\n","\t\t\t\t\t\t\tf_max=None,\n","\t\t\t\t\t\t\tf_min=None,\n","\t\t\t\t\t\t\tn_fft=None,\n","\t\t\t\t\t\t\twin_length=None,\n","\t\t\t\t\t\t\trepresentation=None,\n","\t\t\t\t\t\t\ttransform=None,\n","\t\t\t\t\t\t\taugmentation=None,\n","\t\t\t\t\t\t\tfragment=None\n","\t\t\t\t\t\t):\n","\n","\t\tspecies = np.load(default_labels_path)\n","\t\tspecies_list = species.tolist()\n","\n","\t\tlist1 = []\n","\t\tlist2 = []\n","\n","\t\tif fragment == True:\n","\t\t\tfor path in glob(os.path.join(root_dir, data_dir, '*.wav')):\n","\t\t\t\t\tfile_ID = ntpath.basename(path)\n","\t\t\t\t\tspecies_ID = file_ID.split('_')[0]\n","\t\t\t\t\tlist1.append(os.path.join(data_dir, file_ID)) #filenames\n","\t\t\t\t\tlist2.append(species_ID) #target classes\n","\n","\n","\t\tif fragment == False:\n","\t\t\tfor path in data_dir:\n","\t\t\t\tfile_ID = ntpath.basename(path)\n","\t\t\t\tspecies_ID = file_ID.split('_')[0]\n","\t\t\t\tlist1.append(path) #filenames\n","\t\t\t\tlist2.append(species_ID) #target classes\n","\n","\t\t# Assigning variables:\n","\t\tself.representation, self.hop_length, self.top_db, self.f_max, self.f_min = representation, hop_length, top_db, f_max, f_min\n","\t\tself.n_fft, self.win_length, self.root_dir, self.transform, self.datalist = n_fft, win_length, root_dir, transform, list1\n","\t\tself.labels, self.default_labels, self.n_bins, self.augmentation, self.fragment = list2, species_list, n_bins, augmentation, fragment\n","\n","\n","\tdef __len__(self):\n","\t\t\"\"\" set the len(object) funciton \"\"\"\n","\t\treturn len(self.datalist)\n","\n","\tdef __getitem__(self, idx):\n","\t\t\"\"\"\n","\t\tFunction to extract the spectrogram samples and labels from the audio dataset.\n","\t\t\"\"\"\n","\t\tif self.fragment == True:\n","\t\t\twav_name = os.path.join(self.root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.datalist[idx])\n","\n","\t\tif self.fragment == False:\n","\t\t\twav_name = self.datalist[idx]\n","\n","\t\taudioContainer = dcase_util.containers.AudioContainer().load(filename=wav_name, fs=44100)\n","\t\taudio = audioContainer.data\n","\t\tsr = audioContainer.fs\n","\n","\t\taudio = torch.tensor(audio).to(torch.float32)\n","\n","\n","\t\tif self.augmentation == True:\n","\n","\n","\t\t\taudio_torch = torch.tensor(audio)\n","\n","\t\t\twave_transforms = Compose([OneOf([NoiseInjection(p=1, max_noise_level=0.04),\n","\t\t\t                                  GaussianNoise(p=1, min_snr=5, max_snr=20),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPinkNoise(p=1, min_snr=5, max_snr=20)],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tp=0.15),])\n","\n","\n","\t\t\taudio_transform = wave_transforms(audio_torch, sr)\n","\t\t\taudio_unsqueezed = audio_transform.unsqueeze(0).unsqueeze(0)\n","\t\t\tadd_IR = ApplyImpulseResponse(p=0.15, p_mode='per_example', sample_rate=44100, mode='per_example', compensate_for_propagation_delay=True, ir_paths=glob('/content/drive/MyDrive/Thesis/sub-spectrogram insect/baseline 1/irs/*/mono/*')) # Add path to impulse response files\n","\t\t\taudio_impulse = add_IR(audio_unsqueezed)\n","\t\t\taudio = audio_impulse.squeeze(0).squeeze(0).to(torch.float32)\n","\n","\n","\n","\t\tif self.representation == 'LINEAR':\n","\t\t\tspec = torchaudio.transforms.Spectrogram(n_fft=self.n_fft, hop_length=self.hop_length, win_length=self.win_length, power=2, normalized=True)(audio)\n","\t\t\tspec_db = torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)(spec)\n","\t\t\tspec_db = spec_db.unsqueeze(0).unsqueeze(0)\n","\t\t\tspec_db = F.interpolate(spec_db, size=(n_bins, spec_db.shape[3]), mode='bicubic', align_corners=False, antialias=True)\n","\t\t\tlogmel = spec_db.squeeze(0).squeeze(0)\n","\n","\n","\n","\t\telif self.representation == 'MEL':\n","\t\t\tspec = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=self.n_fft, hop_length=self.hop_length, win_length=self.win_length, n_mels=self.n_bins, power=2, normalized=True, f_min=self.f_min, f_max=self.f_max )(audio)\n","\t\t\tlogmel = torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)(spec)\n","\n","\n","\t\tlogmel = np.reshape(logmel, [1, logmel.shape[0], logmel.shape[1], 1])\n","\n","\t\tlabel = np.asarray(self.default_labels.index(self.labels[idx]))\n","\n","\n","\t\tsample = {'data': logmel.numpy(), 'label': label}\n","\n","\t\tif self.transform:\n","\t\t\tsample = self.transform(sample)\n","\n","\t\treturn sample"],"metadata":{"id":"E85l3O7uSjnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data_loaders(train_batch_size=None,\n","                     test_batch_size=None,\n","                     sub_spectrogram_size=None,\n","                     hop_size=None,\n","                     n_bins=None,\n","                     use_cuda=None,\n","                     root_dir=None,\n","                     train_dir=None,\n","                     val_dir=None,\n","                     default_labels_path=None,\n","                     hop_length=None,\n","                     top_db=None,\n","                     f_max=None,\n","                     f_min=None,\n","                     n_fft=None,\n","                     win_length=None,\n","                     representation=None):\n","\n","\tkwargs = {'num_workers': 8, 'pin_memory': True} if use_cuda else {'num_workers': 8}\n","\n","\n","\t# Data transformation:\n","\tdata_transform = transforms.Compose([ToTensor(), ToSubSpectrograms(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins)])\n","\n","\tdcase_train = InsectDataset(data_dir=train_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir=root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=True,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=True)\n","\n","\tdcase_val = InsectDataset(data_dir=val_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir=root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=False,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=True)\n","\n","\n","\ttrain_loader = torch.utils.data.DataLoader(dcase_train, batch_size=train_batch_size, shuffle=True, **kwargs)\n","\n","\tval_loader = torch.utils.data.DataLoader(dcase_val, batch_size=test_batch_size, shuffle=False, **kwargs)\n","\n","\n","\treturn train_loader, val_loader\n"],"metadata":{"id":"wOsbyiCPSg6I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_batch(batch, device=None, non_blocking=False):\n","\t\"\"\"\n","\tInbuilt function in the ignite._utils, for converting the data to tensors.\n","\tReturns the tensors of the input data, using convert_tensor function.\n","\t\"\"\"\n","\n","\tx, y = batch\n","\treturn (convert_tensor(x, device=device, non_blocking=non_blocking),\n","\t\tconvert_tensor(y, device=device, non_blocking=non_blocking))"],"metadata":{"id":"24kroOOjSq8u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVkKural-Uo3"},"source":["## 3. Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Calr0I5rSEBl"},"outputs":[],"source":["class SubSpectralNet(nn.Module):\n","\tdef __init__(self, sub_spectrogram_size=None, hop_size=None, n_bins=None, use_cuda=None):\n","\n","\t\tsuper(SubSpectralNet, self).__init__()\n","\t\tself.sub_spectrogram_size, self.hop_size, self.n_bins, self.use_cuda = sub_spectrogram_size, hop_size, n_bins, use_cuda\n","\n","\t\tself.n_sub_spectrograms = 0\n","\t\twhile(self.hop_size*self.n_sub_spectrograms <= self.n_bins - self.sub_spectrogram_size):\n","\t\t\tself.n_sub_spectrograms = self.n_sub_spectrograms + 1\n","\n","\t\tprint('The number of sub-spectrograms (global excluded) =', self.n_sub_spectrograms)\n","\n","\t\t# Initialize EfficientNetV2S models for each sub-spectrogram:\n","\t\tself.efficientnets = nn.ModuleList([create_model('tf_efficientnetv2_s.in21k', pretrained=True, num_classes=66, in_chans=1) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.fcGlobal = []\n","\t\tself.fcGlobal.append(nn.Linear(66*self.n_sub_spectrograms, 66))\n","\t\tself.fcGlobal = nn.ModuleList(self.fcGlobal)\n","\n","\tdef forward(self, x):\n","\t\tlogits = []\n","\t\tintermediate = []\n","\t\tx = x.float()\n","\n","\t\tif self.use_cuda:\n","\t\t\tx = x.cuda()\n","\t\tinput_var = x\n","\n","\t\tfor i in range(x.shape[4]):\n","\t\t\tx = input_var\n","\t\t\tx = self.efficientnets[i](x[:, :, :, :, i])\n","\t\t\tintermediate.append(x)\n","\t\t\tx = x.view(-1, 1, 66)\n","\t\t\tlogits.append(x)\n","\n","\t\tx = torch.cat(intermediate, 1)\n","\t\tfor i in range(len(self.fcGlobal)):\n","\t\t\tx = self.fcGlobal[i](x)\n","\n","\t\tx = x.view(-1, 1, 66)\n","\t\tlogits.append(x)\n","\t\tlogits = torch.cat(logits, 1)\n","\t\treturn logits\n"]},{"cell_type":"markdown","metadata":{"id":"1nEPHnc1-sTl"},"source":["## 4. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPHDPw6o5-cx"},"outputs":[],"source":["def run(train_batch_size=None,\n","        test_batch_size=None,\n","        epochs=None,\n","        lr=None,\n","        weight_decay=None,\n","        log_interval=None,\n","        save_dir=None,\n","        name_model=None,\n","        sub_spectrogram_size=None,\n","        hop_size=None,\n","        n_bins=None,\n","        root_dir=None,\n","        train_dir=None,\n","        val_dir=None,\n","        default_labels_path=None,\n","        hop_length=None,\n","        top_db=None,\n","        f_min=None,\n","        f_max=None,\n","        n_fft=None,\n","        win_length=None,\n","        early_stopping=None,\n","        patience=None,\n","        representation=None,\n","        n_classifiers=None,\n","        save_model=None):\n","\n","\n","    # Enable GPU if possible:\n","    use_cuda = torch.cuda.is_available()\n","    print('Using GPU =', use_cuda)\n","    device = torch.device('cuda' if use_cuda else 'cpu')\n","\n","    # Load custom class weights:\n","    class_weights_np = np.load('/content/drive/MyDrive/Thesis/sub-spectrogram insect/baseline 1/class_weights_2.npy')\n","    class_weights_64 = torch.from_numpy(class_weights_np)\n","    class_weights = class_weights_64.to(torch.float32).to(device)\n","\n","    # Load the data loaders\n","    train_loader, val_loader = get_data_loaders(train_batch_size=train_batch_size,\n","                                                test_batch_size=test_batch_size,\n","                                                sub_spectrogram_size=sub_spectrogram_size,\n","                                                hop_size=hop_size,\n","                                                n_bins=n_bins,\n","                                                use_cuda=use_cuda,\n","                                                root_dir=root_dir,\n","                                                train_dir=train_dir,\n","                                                val_dir=val_dir,\n","                                                default_labels_path=default_labels_path,\n","                                                hop_length=hop_length,\n","                                                top_db=top_db,\n","                                                f_max=f_max,\n","                                                f_min=f_min,\n","                                                n_fft=n_fft,\n","                                                win_length=win_length,\n","                                                representation=representation)\n","\n","    # Get the model\n","    model = SubSpectralNet(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins, use_cuda=use_cuda).to(device)\n","\n","    # Init the optimizer\n","    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = CosineAnnealingLR(optimizer, eta_min=1.0e-9, T_max=epochs)\n","\n","    def update_model(engine, batch): #Adapted to match baseline 2\n","        \"\"\"Prepare batch for training: pass to a device with options.\"\"\"\n","        model.train()\n","        inputs, label = prepare_batch(batch, device=device)\n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        losses = []\n","\n","        for ite in range(output.shape[1]):\n","            losses.append(F.cross_entropy(output[:,ite,:], label, weight=class_weights, label_smoothing=0.1))\n","\n","        loss = sum(losses)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        return losses, output, label\n","\n","\n","    # get the trainer module\n","    trainer = Engine(update_model)\n","\n","\n","    def evaluate(engine, batch):\n","        \"\"\"Prepare batch for evaluation: pass to a device with options.\"\"\"\n","        model.eval()\n","        with torch.no_grad():\n","            inputs, label = prepare_batch(batch, device=device)\n","\n","            output = model(inputs)\n","\n","            losses = []\n","            for ite in range(output.shape[1]):\n","                losses.append(F.cross_entropy(output[:,ite,:], label, weight=class_weights, reduction='sum', label_smoothing=0.1).item())\n","\n","        return losses, output, label\n","\n","    # get the evaluator module:\n","    evaluator = Engine(evaluate)\n","\n","\n","\n","    output_transforms = {}\n","    for subSpec in range(n_classifiers):\n","        def output_transform(output, subSpec=subSpec):\n","            losses, correct, label = output\n","            return correct[:, subSpec, :], label\n","        output_transforms[f'output_transform{subSpec}'] = output_transform\n","\n","    metrics = {}\n","    for transform_name, transform_func in output_transforms.items():\n","        metrics[transform_name] = {\n","            'accuracy': Accuracy(output_transform=transform_func),\n","            'loss': Loss(F.cross_entropy, output_transform=transform_func),\n","            'f1': F1Score(output_transform=transform_func)\n","\n","        }\n","\n","\n","    for metric_key, metric_group in metrics.items():\n","        if isinstance(metric_group, dict):\n","            for name, metric in metric_group.items():\n","                metric.attach(evaluator, f'{name}_{metric_key}')\n","        else:\n","            metric_group.attach(evaluator, metric_key)\n","\n","\n","    # Log the events in Ignite: EVERY ITERATION\n","    @trainer.on(Events.ITERATION_COMPLETED)\n","    def log_training_loss(engine):\n","        iter = (engine.state.iteration - 1) % len(train_loader) + 1\n","        if iter % log_interval == 0:\n","            losses, output, label = engine.state.output\n","            epoch = engine.state.epoch\n","            message = [f'Train Epoch: {epoch} [{iter}/{len(train_loader)}]']\n","            for subSpec in range(output.shape[1]):\n","              if subSpec == (output.shape[1])-1:\n","                message.append(f'Losses: {round(losses[subSpec].item(), 2)} (Global Classifier)')\n","              else:\n","                message.append(f'Losses: {round(losses[subSpec].item(), 2)} (Sub-classifier {subSpec+1})')\n","            print(message)\n","\n","\n","\n","    # Log the events in Ignite: Test the validation data on EVERY EPOCH\n","    @trainer.on(Events.EPOCH_COMPLETED)\n","    def log_validation_results(engine):\n","\n","        evaluator.run(val_loader)\n","        metrics_results = evaluator.state.metrics\n","        epoch = engine.state.epoch\n","\n","        #LOSS\n","        message = [f'Validation Results - Epoch: {epoch}, Loss:    ']\n","        for subSpec in range(n_classifiers):\n","          loss_metric_key = f'loss_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[loss_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[loss_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","        #ACC\n","        message = [f'Validation Results - Epoch: {epoch}, Accuracy:']\n","        for subSpec in range(n_classifiers):\n","          accuracy_metric_key = f'accuracy_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[accuracy_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[accuracy_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","        #F1\n","        message = [f'Validation Results - Epoch: {epoch}, F1-score:']\n","        for subSpec in range(n_classifiers):\n","          f1_metric_key = f'f1_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[f1_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[f1_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","\n","\n","    if early_stopping == True:\n","      def score_function(engine):\n","        val_F1 = engine.state.metrics[f'f1_output_transform{n_classifiers-1}']\n","        return val_F1\n","\n","      # Initialize EarlyStopping\n","      early_stopping_mechanism = EarlyStopping(patience=patience, score_function=score_function, trainer=trainer)\n","\n","      # Attach the early stopping handler to the evaluation engine\n","      evaluator.add_event_handler(Events.COMPLETED, early_stopping_mechanism)\n","\n","\n","    if save_model:\n","      # Save raw data as json\n","      log_dir = '/content/drive/MyDrive/Thesis/sub-spectrogram insect/baseline 1/results'\n","      os.makedirs(log_dir, exist_ok=True)\n","\n","      # Model checkpointing\n","      checkpoint_handler = ModelCheckpoint(\n","          dirname=log_dir,\n","          filename_prefix=name_model,\n","          create_dir=True,\n","          require_empty=False,\n","          score_function=score_function,\n","          score_name= f'val_f1',\n","          global_step_transform=lambda engine, event: engine.state.epoch,\n","          filename_pattern='{filename_prefix}_{score_name}={score}.{ext}'\n","      )\n","\n","      # Attach the handler to the evaluator and trainer\n","      evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model_best': model})\n","\n","    trainer.run(train_loader, max_epochs=epochs)\n","    directory_results = os.path.join(log_dir, name_model + '.json')\n","\n","    # return the model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgFHOjajE6V_"},"outputs":[],"source":["# General hyperparameters:\n","train_batch_size = 32\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch size training.\n","test_batch_size = 32\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch size testing.\n","lr = 0.0017\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Learning rate.\n","weight_decay = 0.00001\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Weight decay.\n","epochs = 50\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of epochs.\n","\n","# Spectrogram hyperparameters:\n","representation = 'LINEAR'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Spectrogram representation method (LINEAR/MEL).\n","n_bins = 128\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of frequency bins.\n","n_fft = 2048\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of FFTs.\n","hop_length = round(n_fft/2)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Hop length.\n","win_length = n_fft\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Window length.\n","f_min = 400\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Minimum frequency (hz).\n","f_max = 30000\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Maximum frequency (hz).\n","top_db = 80\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Top decibel (dB).\n","\n","# Sub-spectrogram hyperparameters:\n","number_sub_spectrograms = 2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Specify the number of sub-spectrograms.\n","sub_spectrogram_size = (n_bins//number_sub_spectrograms)\t# Sub-spectrogram size.\n","hop_size = sub_spectrogram_size\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Hop size, could be changed to work with gaps or overlap.\n","\n","# Directories:\n","default_labels_path = '......./sorted_species.npy'\t\t\t\t# Directory to the attached sorted species file.\n","root_dir = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Root directory.\n","train_dir = 'train'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory to training data.\n","val_dir = 'val'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory to validation data.\n","\n","# Mode:\n","name_model = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Name of the model.\n","train = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Train a new model (True/False).\n","log_interval = 50\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Logging interval of training loss.\n","early_stopping = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Enable early stopping mechanism (True/False).\n","patience = 10\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Patience for early stopping.\n","save_model = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Save the newly tarined model (True/False).\n","save_dir = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory where to save the new model and results.\n","test = False\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Train a model (True/False).\n","model_to_test = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Name of model to be evaluated.\n","\n","# Calculate how many classifiers we are working with:\n","n_classifiers = classifier_calculator(n_bins=n_bins, sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size)\n","print('Data representation method =', representation, 'spectrograms')\n","\n","# Start training mechanism:\n","if train:\n","\t# Run the model:\n","\tmodel = run(\n","\t\t\ttrain_batch_size=train_batch_size,\n","\t\t\ttest_batch_size=test_batch_size,\n","\t\t\tepochs=epochs,\n","\t\t\tlr=lr,\n","\t\t\tweight_decay=weight_decay,\n","\t\t\tlog_interval=log_interval,\n","\t\t\tsave_dir=save_dir,\n","\t\t\tname_model=name_model,\n","\t\t\tsub_spectrogram_size=sub_spectrogram_size,\n","\t\t\thop_size=hop_size,\n","\t\t\tn_bins=n_bins,\n","\t\t\troot_dir=root_dir,\n","\t\t\ttrain_dir=train_dir,\n","\t\t\tval_dir=val_dir,\n","\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\thop_length=hop_length,\n","\t\t\ttop_db=top_db,\n","\t\t\tf_min=f_min,\n","\t\t\tf_max=f_max,\n","\t\t\tn_fft=n_fft,\n","\t\t\twin_length=win_length,\n","\t\t\tearly_stopping=early_stopping,\n","\t\t\tpatience=patience,\n","\t\t\trepresentation=representation,\n","\t\t\tn_classifiers=n_classifiers,\n","\t\t\tsave_model=save_model\n","\t)\n","\n","\t# Save the model of the last epoch:\n","\tif save_model:\n","\t\tdir = os.path.join(save_dir, f'{name_model}_last_epoch.pt')\n","\t\ttorch.save(model, dir)\n","\n","# Start testing mechanism:\n","if test:\n","\t# Use GPU if available:\n","\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","\t# Empty GPU if available:\n","\tif device == 'cuda':\n","\t\ttorch.cuda.empty_cache()\n","\n","\tuse_cuda = True if device == 'cuda' else False\n","\n","\t# Initialize the model:\n","\tmodel = SubSpectralNet(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins, use_cuda=use_cuda)\n","\n","\t# Load the state dictionary:\n","\tstate_dict = torch.load(os.path.join(save_dir, model_to_test), map_location=torch.device(device))\n","\n","\t# Apply the state dictionary:\n","\tmodel.load_state_dict(state_dict)\n","\n","\t# Move model to GPU if available:\n","\tmodel = model.eval().to(device)\n","\n","\t# Specify keyword arguments for dataloader:\n","\tkwargs = {'num_workers': 8, 'pin_memory': True} if device == 'cuda' else {'num_workers': 8}\n","\n","\t# Specify data transform for the InsectData function:\n","\tdata_transform = transforms.Compose([ToTensor(), ToSubSpectrograms(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins)])\n","\n","\t# Create a test dataframe that contains the paths to the test recordings:\n","\ttest_df = pd.read_csv('....../metadata.csv')\n","\ttest_df = test_df[test_df['subset']=='test']\n","\ttest_df['path'] = test_df['path'].str.replace('data', '/content/drive/MyDrive/Thesis')\n","\n","\t# Create a dictionary for saving the full predictions and the true labels:\n","\tprediction_output = {'full_predictions':[], 'true_label':[]}\n","\n","\tfor i in tqdm(range(len(test_df))):\n","\t\tname = ntpath.basename(test_df.iloc[i]['path'][:-4]) # Extracts all basenames of the full files.\n","\t\tdata = glob(f'................../test/{name}_*.wav') # Gathers all fragments with the same basename from the test file directory.\n","\t\tdf = pd.DataFrame(data, columns=['path']) \t\t\t\t\t # Create a new temporary df with all fragments of one recording.\n","\t\tdf = df['path'].tolist()\n","\n","\t\tpred_ds = InsectDataset(data_dir=df,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir= '',\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=False,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=False)\n","\n","\t\ttest_loader = torch.utils.data.DataLoader(pred_ds, batch_size=100, shuffle=False, **kwargs)\n","\n","\t\twith torch.no_grad():\n","\t\t\tfor batch in test_loader:\n","\t\t\t\tpreds = []\n","\t\t\t\tinputs, label = prepare_batch(batch, device=device)\n","\t\t\t\toutput = model(inputs)\n","\t\t\t\tfor sample in range(len(label)):\n","\t\t\t\t\tpreds.append(output[sample,(n_classifiers-1),:].cpu().numpy())\n","\t\t\t\tpreds_mean = np.mean(preds, axis=0)\n","\t\t\t\tfull_prediction = np.argmax(preds_mean)\n","\t\t\t\tprediction_output['full_predictions'].append(int(full_prediction))\n","\t\t\t\tprediction_output['true_label'].append(int(label[0].item()))\n","\n","\tpredictions = prediction_output['full_predictions']\n","\ttrue_labels = prediction_output['true_label']\n","\n","\tcm = confusion_matrix(true_labels, predictions)\n","\tnp.save(os.path.join(save_dir, f'{name_model}_confusion_matrix_raw.npy'), cm)\n","\n","\treport = classification_report(true_labels, predictions, digits=3, output_dict=True)\n","\tevaluation = pd.DataFrame(report).transpose()\n","\tevaluation.to_csv(os.path.join(save_dir, f'{name_model}_test_evaluation.csv'))\n","\n","\t# Calculate the macro F1 score for direct output:\n","\tmacro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=1)\n","\n","\t# Save the prediction_output to a JSON file:\n","\twith open(os.path.join(save_dir, f'{name_model}_prediction_and_true_label_raw.json'), 'w') as f:\n","\t\tjson.dump(prediction_output, f)\n","\n","\tprint(f'Macro F1 Score: {macro_f1}')\n"]}],"metadata":{"colab":{"collapsed_sections":["qvTlKYFN-M1c","cma8U1MrKC6-","dASIioVx6qGD","7Q-JvnFR9o2n","lVkKural-Uo3","1nEPHnc1-sTl"],"provenance":[],"authorship_tag":"ABX9TyOabbthMqt1upsWACeebbDE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}