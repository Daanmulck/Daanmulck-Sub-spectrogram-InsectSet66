{"cells":[{"cell_type":"markdown","metadata":{"id":"zu-6tWSj9xqQ"},"source":["# **Model 2**"]},{"cell_type":"markdown","metadata":{"id":"qvTlKYFN-M1c"},"source":["## 1. Python packages and custom functions"]},{"cell_type":"markdown","source":["### 1.1 Python packages"],"metadata":{"id":"1UolYhhnKAGe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsHEsn2e_O8-"},"outputs":[],"source":["%%capture\n","!pip install dcase_util\n","!pip install pytorch-ignite\n","!pip install torch_audiomentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bu4bWFZE98PD"},"outputs":[],"source":["# Required functions/packages:\n","\n","# General:\n","import numpy as np\n","import pandas as pd\n","import os\n","import ntpath\n","import random\n","import json\n","import math\n","import dcase_util\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","from tqdm import tqdm\n","from glob import glob\n","\n","# PyTorch:\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torchaudio\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","from ignite._utils import convert_tensor\n","from torch_audiomentations import AddColoredNoise, ApplyImpulseResponse\n","from torch.nn import init\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","# Ignite Framework:\n","from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n","from ignite.metrics import Accuracy, Loss, MetricsLambda, Metric\n","from ignite.handlers import ModelCheckpoint, EarlyStopping\n","from ignite._utils import convert_tensor\n","\n","# Ignore warnings:\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Determinism Settings (comment out for a non-deterministic run):\n","seed = 1000\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"markdown","metadata":{"id":"3uNcY-EGR21E"},"source":["### 1.2 Custom Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6uL2IraR2oD"},"outputs":[],"source":["class F1Score(Metric):\n","\n","    def __init__(self, *args, **kwargs):\n","        self.f1 = 0\n","        self.count = 0\n","        super().__init__(*args, **kwargs)\n","\n","    def update(self, output):\n","        y_pred, y = output[0].detach(), output[1].detach()\n","\n","        _, predicted = torch.max(y_pred, 1)\n","        f = f1_score(y.cpu(), predicted.cpu(), average='macro', zero_division=1)\n","        self.f1 += f\n","        self.count += 1\n","\n","    def reset(self):\n","        self.f1 = 0\n","        self.count = 0\n","        super(F1Score, self).reset()\n","\n","    def compute(self):\n","        return self.f1 / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zh9gJJFLR8BX"},"outputs":[],"source":["def classifier_calculator(n_bins=None, sub_spectrogram_size=None, hop_size=None):\n","  n_classifiers = 0\n","  bins_per_sub = []\n","  size = sub_spectrogram_size\n","  start = 0\n","  while(hop_size*n_classifiers <= n_bins - sub_spectrogram_size):\n","    n_classifiers = n_classifiers + 1\n","    bins_per_sub.append([start,size])\n","    start += hop_size\n","    size += hop_size\n","\n","  # + 1 for global classifier:\n","  n_classifiers = n_classifiers + 1\n","  bins_per_sub.append(['GLOBAL'])\n","  print('Total number of classifiers (global included) =', n_classifiers)\n","\n","  # Sub-spectrogram bin range:\n","  print(bins_per_sub)\n","\n","  return n_classifiers"]},{"cell_type":"markdown","metadata":{"id":"7Q-JvnFR9o2n"},"source":["## 2. Loading and transforming data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-slbziINkqC"},"outputs":[],"source":["\"\"\"\n","This script contains the basic building blocks of the DataLoader and Transforms for preprocessing the data in batches.\n","\n","Updated February 2019\n","Sai Samarth R Phaye\n","\"\"\"\n","\n","class ToTensor(object):\n","\t\"\"\" Convert ndarrays in sample to Tensors.\"\"\"\n","\n","\tdef __call__(self, sample):\n","\t\tdata, label = sample['data'], sample['label']\n","\n","\t\t# swap color axis (not required)\n","\t\tdata = data.transpose((0, 1, 2, 3))\n","\n","\t\treturn {'data': torch.from_numpy(data),\n","\t\t\t\t'label': torch.from_numpy(label)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MquJKTxNws1"},"outputs":[],"source":["\n","class ToSubSpectrograms(object):\n","\t\"\"\" Generate Sub-Spectrogram Tensors \"\"\"\n","\tdef __init__(self, sub_spectrogram_size=None, hop_size=None, n_bins=None):\n","\t\t\"\"\"\n","\t\tParameters\n","\t\t----------\n","\t\tsub_spectrogram_size : int\n","\t\t\tSize of the SubSpectrogram. Default: 20\n","\n","\t\thop_size : int\n","\t\t\tMel-bin hop size of the SubSpectrogram. Default 10\n","\n","\t\tn_bins : int\n","\t\t\tNumber of mel-bins of the Spectrogram extracted. Default: 40.\n","\t\t\"\"\"\n","\t\tself.sub_spectrogram_size, self.hop_size, self.n_bins = sub_spectrogram_size, hop_size, n_bins\n","\n","\tdef __call__(self, sample):\n","\t\t\"\"\"\n","\t\tParameters\n","\t\t----------\n","\t\tsample : PyTorch tensor\n","\t\t\tThe input tensor data and label\n","\t\tReturns\n","\t\t-------\n","\t\tsub_spectrograms: tensor\n","\t\t\tA list of sub-spectrograms. Default size [channels, sub_spectrogram_size, time_indices, n_sub_spectrograms]\n","\t\tlabel: tensor\n","\t\t\tCorresponding label\n","\t\t\"\"\"\n","\t\tspectrogram, label = sample['data'], sample['label']\n","\n","\t\ti = 0\n","\t\tsub_spectrograms = torch.from_numpy(np.asarray([]))\n","\t\twhile(self.hop_size*i <= self.n_bins - self.sub_spectrogram_size):\n","\n","\t\t\t# Extract a Sub-Spectrogram\n","\t\t\tsubspectrogram = spectrogram[:,i*self.hop_size:i*self.hop_size+self.sub_spectrogram_size,:, :]\n","\n","\t\t\tif i == 0:\n","\t\t\t\tsub_spectrograms = subspectrogram\n","\t\t\telse:\n","\t\t\t\tsub_spectrograms = torch.cat((subspectrogram, sub_spectrograms), 3)\n","\n","\t\t\ti = i + 1\n","\n","\t\treturn sub_spectrograms, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3HSgMxwPO6F"},"outputs":[],"source":["class InsectDataset(Dataset):\n","\t\"\"\" DCASE 2018 Dataset extraction \"\"\"\n","\n","\tdef __init__(self,\n","\t            data_dir=None,\n","\t\t\t\t\t\t\troot_dir=None,\n","\t\t\t\t\t\t\tdefault_labels_path=None,\n","\t\t\t\t\t\t\tn_bins=None,\n","\t\t\t\t\t\t\thop_length=None,\n","\t\t\t\t\t\t\ttop_db=None,\n","\t\t\t\t\t\t\tf_max=None,\n","\t\t\t\t\t\t\tf_min=None,\n","\t\t\t\t\t\t\tn_fft=None,\n","\t\t\t\t\t\t\twin_length=None,\n","\t\t\t\t\t\t\trepresentation=None,\n","\t\t\t\t\t\t\ttransform=None,\n","\t\t\t\t\t\t\taugmentation=None,\n","\t\t\t\t\t\t\tfragment=None\n","\t\t\t\t\t\t):\n","\n","\n","\t\tspecies = np.load(default_labels_path)\n","\t\tspecies_list = species.tolist()\n","\n","\t\tlist1 = []\n","\t\tlist2 = []\n","\n","\t\tif fragment == True:\n","\t\t\tfor path in glob(os.path.join(root_dir, data_dir, '*.wav')):\n","\t\t\t\t\tfile_ID = ntpath.basename(path)\n","\t\t\t\t\tspecies_ID = file_ID.split('_')[0]\n","\t\t\t\t\tlist1.append(os.path.join(data_dir, file_ID)) #filenames\n","\t\t\t\t\tlist2.append(species_ID) #target classes\n","\n","\n","\t\tif fragment == False:\n","\t\t\tfor path in data_dir:\n","\t\t\t\tfile_ID = ntpath.basename(path)\n","\t\t\t\tspecies_ID = file_ID.split('_')[0]\n","\t\t\t\tlist1.append(path) #filenames\n","\t\t\t\tlist2.append(species_ID) #target classes\n","\n","\n","\t\t# Assigning variables:\n","\t\tself.representation, self.hop_length, self.top_db, self.f_max, self.f_min = representation, hop_length, top_db, f_max, f_min\n","\t\tself.n_fft, self.win_length, self.root_dir, self.transform, self.datalist = n_fft, win_length, root_dir, transform, list1\n","\t\tself.labels, self.default_labels, self.n_bins, self.augmentation, self.fragment = list2, species_list, n_bins, augmentation, fragment\n","\n","\n","\tdef __len__(self):\n","\t\t\"\"\" set the len(object) funciton \"\"\"\n","\t\treturn len(self.datalist)\n","\n","\tdef __getitem__(self, idx):\n","\t\t\"\"\"\n","\t\tFunction to extract the spectrogram samples and labels from the audio dataset.\n","\t\t\"\"\"\n","\n","\t\tif self.fragment == True:\n","\t\t\twav_name = os.path.join(self.root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.datalist[idx])\n","\n","\t\tif self.fragment == False:\n","\t\t\twav_name = self.datalist[idx]\n","\n","\n","\t\taudioContainer = dcase_util.containers.AudioContainer().load(filename=wav_name, fs=44100)\n","\t\taudio = audioContainer.data\n","\t\tsr = audioContainer.fs\n","\n","\t\taudio = torch.tensor(audio).to(torch.float32)\n","\n","\t\tif self.augmentation == True:\n","\t\t\taudio = audio.unsqueeze(0).unsqueeze(0)\n","\t\t\tadd_colored_noise = AddColoredNoise(p=0.9, p_mode='per_example', mode='per_example', sample_rate=sr, min_snr_in_db=25, max_snr_in_db=40, min_f_decay=-2, max_f_decay=1.5)\n","\t\t\taudio_noise = add_colored_noise(audio)\n","\t\t\tadd_IR = ApplyImpulseResponse(p=0.7, p_mode='per_example', sample_rate=44100, mode='per_example', compensate_for_propagation_delay=True, ir_paths='/content/drive/MyDrive/Thesis/baseline 2/irs') # Add path to impulse response files\n","\t\t\taudio_impulse = add_IR(audio_noise)\n","\t\t\tmix_ratio = random.uniform(0, 1)\n","\t\t\taudio_augmented = (mix_ratio * audio_noise) + ((1 - mix_ratio) * audio_impulse)\n","\t\t\taudio = audio_augmented.squeeze(0).squeeze(0).to(torch.float32)\n","\n","\n","\t\tif self.representation == 'LINEAR':\n","\t\t\tspec = torchaudio.transforms.Spectrogram(n_fft=self.n_fft, hop_length=self.hop_length, win_length=self.win_length)(audio)\n","\t\t\tspec_db = torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)(spec)\n","\t\t\tspec_db = spec_db.unsqueeze(0).unsqueeze(0)\n","\t\t\tspec_db = F.interpolate(spec_db, size=(n_bins, spec_db.shape[3]), mode='bicubic', align_corners=False, antialias=True)\n","\t\t\tlogmel = spec_db.squeeze(0).squeeze(0)\n","\n","\t\telif self.representation == 'MEL':\n","\t\t\tspec = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=self.n_fft, hop_length=self.hop_length, win_length=self.win_length, n_mels=self.n_bins, f_min=self.f_min, f_max=self.f_max)(audio)\n","\t\t\tlogmel = torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)(spec)\n","\n","\t\tlogmel = np.reshape(logmel, [1, logmel.shape[0], logmel.shape[1], 1])\n","\n","\n","\n","\t\t# print('Shape of input spectrogram = ', logmel.shape)\n","\t\tif logmel.shape != (1, 64, 1501, 1):\n","\t\t\t# print(\"PADDING NEEDED FOR\", logmel.shape, wav_name)\n","\t\t\t# Calculate the padding needed\n","\t\t\tpadding = [(0, 0), (0, 0), (0, 1), (0, 0)]\n","\n","\t\t\t# Pad the spectrogram\n","\t\t\tlogmel = np.pad(logmel, padding, mode='constant', constant_values=0)\n","\t\t\tlogmel = torch.tensor(logmel).to(torch.float32)\n","\t\t\t# print(logmel.shape, wav_name)\n","\n","\n","\n","\n","\t\tlabel = np.asarray(self.default_labels.index(self.labels[idx]))\n","\n","\n","\n","\t\tsample = {'data': logmel.numpy(), 'label': label}\n","\t\tif self.transform:\n","\t\t\tsample = self.transform(sample)\n","\n","\t\treturn sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmNZVqdyKfqE"},"outputs":[],"source":["def get_data_loaders(train_batch_size=None,\n","                     test_batch_size=None,\n","                     sub_spectrogram_size=None,\n","                     hop_size=None,\n","                     n_bins=None,\n","                     use_cuda=None,\n","                     root_dir=None,\n","                     train_dir=None,\n","                     val_dir=None,\n","                     default_labels_path=None,\n","                     hop_length=None,\n","                     top_db=None,\n","                     f_max=None,\n","                     f_min=None,\n","                     n_fft=None,\n","                     win_length=None,\n","                     representation=None):\n","\n","\tkwargs = {'num_workers': 8, 'pin_memory': True} if use_cuda else {}\n","\n","\n","\t# Data transformation:\n","\tdata_transform = transforms.Compose([ToTensor(), ToSubSpectrograms(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins)])\n","\n","\tdcase_train = InsectDataset(data_dir=train_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir=root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=True,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=True)\n","\n","\tdcase_val = InsectDataset(data_dir=val_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir=root_dir,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=False,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=True)\n","\n","\n","\ttrain_loader = torch.utils.data.DataLoader(dcase_train, batch_size=train_batch_size, shuffle=True, **kwargs)\n","\n","\tval_loader = torch.utils.data.DataLoader(dcase_val, batch_size=test_batch_size, shuffle=False, **kwargs)\n","\n","\n","\treturn train_loader, val_loader\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CV4uiTb1PmOj"},"outputs":[],"source":["def prepare_batch(batch, device=None, non_blocking=False):\n","\t\"\"\"\n","\tInbuilt function in the ignite._utils, for converting the data to tensors.\n","\tReturns the tensors of the input data, using convert_tensor function.\n","\t\"\"\"\n","\n","\tx, y = batch\n","\treturn (convert_tensor(x, device=device, non_blocking=non_blocking),\n","\t\tconvert_tensor(y, device=device, non_blocking=non_blocking))"]},{"cell_type":"markdown","metadata":{"id":"lVkKural-Uo3"},"source":["## 3. Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWIyVg2_-ULy"},"outputs":[],"source":["class SubSpectralNet(nn.Module):\n","\tdef __init__(self, sub_spectrogram_size=None, hop_size=None, n_bins=None, use_cuda=None):\n","\n","\t\tsuper(SubSpectralNet, self).__init__()\n","\t\tself.sub_spectrogram_size, self.hop_size, self.n_bins, self.use_cuda = sub_spectrogram_size, hop_size, n_bins, use_cuda\n","\n","\t\tself.n_sub_spectrograms = 0\n","\t\twhile(self.hop_size*self.n_sub_spectrograms <= self.n_bins - self.sub_spectrogram_size):\n","\t\t\tself.n_sub_spectrograms = self.n_sub_spectrograms + 1\n","\n","\t\tprint('The number of sub-spectrograms (global excluded) =', self.n_sub_spectrograms)\n","\n","\n","\t\t# Conv Layer 1:\n","\t\tself.conv1 = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=(2,2), padding=(2,2)) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.conv1_bn = nn.ModuleList([nn.BatchNorm2d(8) for _ in range(self.n_sub_spectrograms)])\n","\t\tfor i in range(self.n_sub_spectrograms):\n","\t\t\tinit.kaiming_normal_(self.conv1[i].weight, a=0.1)\n","\t\t\tself.conv1[i].bias.data.zero_()\n","\n","\n","\t\t# Conv Layer 2:\n","\t\tself.conv2 = nn.ModuleList([nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(2,2), padding=(1,1)) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.conv2_bn = nn.ModuleList([nn.BatchNorm2d(16) for _ in range(self.n_sub_spectrograms)])\n","\t\tfor i in range(self.n_sub_spectrograms):\n","\t\t\tinit.kaiming_normal_(self.conv2[i].weight, a=0.1)\n","\t\t\tself.conv2[i].bias.data.zero_()\n","\n","\t\t# Conv layer 3:\n","\t\tself.conv3 = nn.ModuleList([nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(2,2), padding=(1,1)) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.conv3_bn = nn.ModuleList([nn.BatchNorm2d(32) for _ in range(self.n_sub_spectrograms)])\n","\t\tfor i in range(self.n_sub_spectrograms):\n","\t\t\tinit.kaiming_normal_(self.conv3[i].weight, a=0.1)\n","\t\t\tself.conv3[i].bias.data.zero_()\n","\n","\t\t# Conv layer 4:\n","\t\tself.conv4 = nn.ModuleList([nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(2,2), padding=(1,1)) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.conv4_bn = nn.ModuleList([nn.BatchNorm2d(64) for _ in range(self.n_sub_spectrograms)])\n","\t\tfor i in range(self.n_sub_spectrograms):\n","\t\t\tinit.kaiming_normal_(self.conv4[i].weight, a=0.1)\n","\t\t\tself.conv4[i].bias.data.zero_()\n","\n","\t\t# Conv layer 5:\n","\t\tself.conv5 = nn.ModuleList([nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1)) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.conv5_bn = nn.ModuleList([nn.BatchNorm2d(128) for _ in range(self.n_sub_spectrograms)])\n","\t\tfor i in range(self.n_sub_spectrograms):\n","\t\t\tinit.kaiming_normal_(self.conv5[i].weight, a=0.1)\n","\t\t\tself.conv5[i].bias.data.zero_()\n","\n","\t\t# Linear layer:\n","\t\tself.ap = nn.ModuleList([nn.AdaptiveAvgPool2d(output_size=1) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.fc1 = nn.ModuleList([nn.Linear(128, 32) for _ in range(self.n_sub_spectrograms)])\n","\n","\t\tself.drop1 = nn.ModuleList([nn.Dropout(0.23) for _ in range(self.n_sub_spectrograms)])\n","\t\tself.fc2 = nn.ModuleList([nn.Linear(32, 66) for _ in range(self.n_sub_spectrograms)])\n","\n","\t\tnumFCs = int(math.log(self.n_sub_spectrograms*32, 2))\n","\t\tneurons = int(math.pow(2, numFCs))\n","\n","\t\tself.fcGlobal = []\n","\t\ttempNeurons =int(32*self.n_sub_spectrograms)\n","\t\tcount = 0\n","\n","\t\twhile(neurons >= 64):\n","\t\t\tcount +=1\n","\t\t\tself.fcGlobal.append(nn.Linear(tempNeurons, neurons))\n","\t\t\tself.fcGlobal.append(nn.Dropout(0.23))\n","\t\t\ttempNeurons = neurons\n","\t\t\tneurons = int(neurons / 2)\n","\n","\t\tprint('Amount of extra fcglobal iterations added =', count)\n","\t\tif count == 0:\n","\t\t\tself.fcGlobal.append(nn.Dropout(0.23))\n","\t\t\tprint('Extra dropout layer added if no extra layers added (0) to ensure the global and sub-spec has the same layers')\n","\n","\t\tself.fcGlobal.append(nn.Linear(tempNeurons, 66))\n","\t\tself.fcGlobal = nn.ModuleList(self.fcGlobal)\n","\n","\n","\tdef forward(self, x):\n","\t\tlogits = []\n","\t\tintermediate = []\n","\t\tx = x.float()\n","\t\tif self.use_cuda:\n","\t\t\tx = x.cuda()\n","\t\tinput_var = x\n","\n","\t\t# For every sub-spectrogram:\n","\t\tfor i in range(x.shape[4]):\n","\n","\t\t\tx = input_var\n","\t\t\tx = self.conv1[i](x[:, :, :, :, i])\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.conv1_bn[i](x)\n","\n","\t\t\tx = self.conv2[i](x)\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.conv2_bn[i](x)\n","\n","\t\t\tx = self.conv3[i](x)\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.conv3_bn[i](x)\n","\n","\t\t\tx = self.conv4[i](x)\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.conv4_bn[i](x)\n","\n","\n","\t\t\tx = self.conv5[i](x)\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.conv5_bn[i](x)\n","\n","\t\t\tx = self.ap[i](x)\n","\t\t\tx = x.view(x.shape[0], -1)\n","\t\t\tx = self.fc1[i](x)\n","\t\t\tintermediate.append(x)\n","\t\t\tx = self.drop1[i](x)\n","\t\t\tx = F.relu(x)\n","\t\t\tx = self.fc2[i](x)\n","\n","\t\t\tx = x.view(-1, 1, 66)\n","\t\t\tlogits.append(x)\n","\n","\t\t# Extracted intermediate layers:\n","\t\tx = torch.cat((intermediate), 1)\n","\n","\t\t# Global classification:\n","\t\tfor i in range(len(self.fcGlobal)):\n","\t\t\tx = self.fcGlobal[i](x)\n","\t\tx = x.view(-1, 1, 66)\n","\t\tlogits.append(x)\n","\n","\t\t# All the outputs (low, mid and high band + global classifier):\n","\t\tlogits = torch.cat((logits), 1)\n","\t\treturn logits\n"]},{"cell_type":"markdown","metadata":{"id":"1nEPHnc1-sTl"},"source":["## 4. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPHDPw6o5-cx"},"outputs":[],"source":["def run(train_batch_size=None,\n","        test_batch_size=None,\n","        epochs=None,\n","        lr=None,\n","        weight_decay=None,\n","        log_interval=None,\n","        save_dir=None,\n","        name_model=None,\n","        sub_spectrogram_size=None,\n","        hop_size=None,\n","        n_bins=None,\n","        root_dir=None,\n","        train_dir=None,\n","        val_dir=None,\n","        default_labels_path=None,\n","        hop_length=None,\n","        top_db=None,\n","        f_min=None,\n","        f_max=None,\n","        n_fft=None,\n","        win_length=None,\n","        early_stopping=None,\n","        patience=None,\n","        representation=None,\n","        n_classifiers=None,\n","        save_model=None):\n","\n","    # Enable GPU if possible:\n","    use_cuda = torch.cuda.is_available()\n","    print('Using GPU =', use_cuda)\n","    device = torch.device('cuda' if use_cuda else 'cpu')\n","\n","    # Load the data loaders:\n","    train_loader, val_loader = get_data_loaders(train_batch_size=train_batch_size,\n","                                                test_batch_size=test_batch_size,\n","                                                sub_spectrogram_size=sub_spectrogram_size,\n","                                                hop_size=hop_size,\n","                                                n_bins=n_bins,\n","                                                use_cuda=use_cuda,\n","                                                root_dir=root_dir,\n","                                                train_dir=train_dir,\n","                                                val_dir=val_dir,\n","                                                default_labels_path=default_labels_path,\n","                                                hop_length=hop_length,\n","                                                top_db=top_db,\n","                                                f_max=f_max,\n","                                                f_min=f_min,\n","                                                n_fft=n_fft,\n","                                                win_length=win_length,\n","                                                representation=representation)\n","\n","    # Get the model:\n","    model = SubSpectralNet(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins, use_cuda=use_cuda).to(device)\n","\n","    # Init the optimizer:\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=int(len(train_loader)), epochs=epochs, anneal_strategy='linear')\n","\n","    def update_model(engine, batch):\n","        \"\"\"Prepare batch for training: pass to a device with options.\"\"\"\n","        model.train()\n","        inputs, label = prepare_batch(batch, device=device)\n","\n","        # Manual normalization:\n","        inputs_m, inputs_s = inputs.mean(), inputs.std()\n","        inputs = (inputs - inputs_m) / inputs_s\n","        optimizer.zero_grad()\n","        output = model(inputs)\n","        losses = []\n","\n","        for ite in range(output.shape[1]):\n","            losses.append(F.cross_entropy(output[:,ite,:], label))\n","\n","        loss = sum(losses)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        return losses, output, label\n","\n","\n","    # Get the trainer module:\n","    trainer = Engine(update_model)\n","\n","\n","    def evaluate(engine, batch):\n","        \"\"\"Prepare batch for evaluation: pass to a device with options.\"\"\"\n","        model.eval()\n","        with torch.no_grad():\n","            inputs, label = prepare_batch(batch, device=device)\n","\n","            # Manual normalization:\n","            inputs_m, inputs_s = inputs.mean(), inputs.std()\n","            inputs = (inputs - inputs_m) / inputs_s\n","\n","            output = model(inputs)\n","\n","            losses = []\n","            for ite in range(output.shape[1]):\n","                losses.append(F.cross_entropy(output[:,ite,:], label, reduction='sum').item())\n","\n","        return losses, output, label\n","\n","    # Get the evaluator module:\n","    evaluator = Engine(evaluate)\n","\n","    output_transforms = {}\n","    for subSpec in range(n_classifiers):\n","        def output_transform(output, subSpec=subSpec):\n","            losses, correct, label = output\n","            return correct[:, subSpec, :], label\n","        output_transforms[f'output_transform{subSpec}'] = output_transform\n","\n","    metrics = {}\n","    for transform_name, transform_func in output_transforms.items():\n","        metrics[transform_name] = {\n","            'accuracy': Accuracy(output_transform=transform_func),\n","            'loss': Loss(F.cross_entropy, output_transform=transform_func),\n","            'f1': F1Score(output_transform=transform_func)\n","\n","        }\n","\n","\n","    for metric_key, metric_group in metrics.items():\n","        if isinstance(metric_group, dict):\n","            for name, metric in metric_group.items():\n","                metric.attach(evaluator, f'{name}_{metric_key}')\n","        else:\n","            metric_group.attach(evaluator, metric_key)\n","\n","\n","\n","\n","    # Log the events in Ignite: EVERY ITERATION:\n","    @trainer.on(Events.ITERATION_COMPLETED)\n","    def log_training_loss(engine):\n","        iter = (engine.state.iteration - 1) % len(train_loader) + 1\n","        if iter % log_interval == 0:\n","            losses, output, label = engine.state.output\n","            epoch = engine.state.epoch\n","            message = [f'Train Epoch: {epoch} [{iter}/{len(train_loader)}]']\n","            for subSpec in range(output.shape[1]):\n","              if subSpec == (output.shape[1])-1:\n","                message.append(f'Losses: {round(losses[subSpec].item(), 2)} (Global Classifier)')\n","              else:\n","                message.append(f'Losses: {round(losses[subSpec].item(), 2)} (Sub-classifier {subSpec+1})')\n","            print(message)\n","\n","\n","\n","    # Log the events in Ignite: Test the validation data on EVERY EPOCH:\n","    @trainer.on(Events.EPOCH_COMPLETED)\n","    def log_validation_results(engine):\n","\n","        evaluator.run(val_loader)\n","        metrics_results = evaluator.state.metrics\n","        epoch = engine.state.epoch\n","\n","        # LOSS:\n","        message = [f'Validation Results - Epoch: {epoch}, Loss:    ']\n","        for subSpec in range(n_classifiers):\n","          loss_metric_key = f'loss_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[loss_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[loss_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","        # ACC:\n","        message = [f'Validation Results - Epoch: {epoch}, Accuracy:']\n","        for subSpec in range(n_classifiers):\n","          accuracy_metric_key = f'accuracy_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[accuracy_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[accuracy_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","        # F1-score:\n","        message = [f'Validation Results - Epoch: {epoch}, F1-score:']\n","        for subSpec in range(n_classifiers):\n","          f1_metric_key = f'f1_output_transform{subSpec}'\n","          if subSpec == (n_classifiers - 1):\n","            message.append(f'{round(metrics_results[f1_metric_key], 2)} (Global Classifier)')\n","          else:\n","            message.append(f'{round(metrics_results[f1_metric_key], 2)} (Sub-classifier) {subSpec + 1})')\n","        print(message)\n","\n","\n","    if early_stopping == True:\n","      def score_function(engine):\n","        val_F1 = engine.state.metrics[f'f1_output_transform{n_classifiers-1}']\n","        return val_F1\n","\n","      # Initialize EarlyStopping:\n","      early_stopping_mechanism = EarlyStopping(patience=patience, score_function=score_function, trainer=trainer)\n","\n","      # Attach the early stopping handler to the evaluation engine:\n","      evaluator.add_event_handler(Events.COMPLETED, early_stopping_mechanism)\n","\n","    if save_model:\n","      # Save raw data as json:\n","      os.makedirs(save_dir, exist_ok=True)\n","\n","      # Model checkpointing:\n","      checkpoint_handler = ModelCheckpoint(\n","          dirname=save_dir,\n","          filename_prefix=name_model,\n","          create_dir=True,\n","          require_empty=False,\n","          score_function=score_function,\n","          score_name= f'val_f1',\n","          global_step_transform=lambda engine, event: engine.state.epoch,\n","          filename_pattern='{filename_prefix}_{score_name}={score}.{ext}'\n","      )\n","\n","      # Attach the handler to the evaluator and trainer:\n","      evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model_best': model})\n","\n","    trainer.run(train_loader, max_epochs=epochs)\n","    directory_results = os.path.join(save_dir, name_model + '.json')\n","\n","    # Return the model:\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgFHOjajE6V_"},"outputs":[],"source":["# General hyperparameters:\n","train_batch_size = 14\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch size training.\n","test_batch_size = 14\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch size testing.\n","lr = 0.001\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Learning rate.\n","weight_decay = 0.001\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Weight decay.\n","epochs = 50\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of epochs.\n","\n","# Spectrogram hyperparameters:\n","representation = 'LINEAR'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Spectrogram representation method (LINEAR/MEL).\n","sample_rate = 44100\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Sample rate\n","n_bins = 64\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of frequency bins.\n","n_fft = 1000\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of FFTs.\n","hop_length = int((sample_rate*5)/1500)\t\t\t\t\t\t\t\t\t\t# Hop length.\n","win_length = hop_length*2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Window length.\n","f_min = 0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Minimum frequency (hz).\n","f_max = sample_rate/2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Maximum frequency (hz).\n","top_db = 80\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Top decibel (dB).\n","\n","# Sub-spectrogram hyperparameters:\n","number_sub_spectrograms = 2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Specify the number of sub-spectrograms.\n","sub_spectrogram_size = (n_bins//number_sub_spectrograms)\t# Sub-spectrogram size.\n","hop_size = sub_spectrogram_size\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Hop size.\n","\n","# Directories:\n","default_labels_path = '......./sorted_species.npy'\t\t\t\t# Directory to the attached sorted species file.\n","root_dir = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Root directory.\n","train_dir = 'train'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory to training data.\n","val_dir = 'val'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory to validation data.\n","\n","# Mode:\n","name_model = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Name of the model.\n","train = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Train a new model (True/False).\n","log_interval = 500\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Logging interval of training loss.\n","early_stopping = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Enable early stopping mechanism (True/False).\n","patience = 10\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Patience for early stopping.\n","save_model = True\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Save thenewly tarined model (True/False).\n","save_dir = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Directory where to save the new model and results.\n","test = False\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Train a model (True/False).\n","model_to_test = ''\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Name of model to be evaluated.\n","\n","\n","\n","# Calculate how many classifiers we are working with:\n","n_classifiers = classifier_calculator(n_bins=n_bins, sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size)\n","print('Data representation method =', representation, 'spectrograms')\n","\n","# Start training mechanism:\n","if train:\n","\t# Run the model:\n","\tmodel = run(\n","\t\t\ttrain_batch_size=train_batch_size,\n","\t\t\ttest_batch_size=test_batch_size,\n","\t\t\tepochs=epochs,\n","\t\t\tlr=lr,\n","\t\t\tweight_decay=weight_decay,\n","\t\t\tlog_interval=log_interval,\n","\t\t\tsave_dir=save_dir,\n","\t\t\tname_model=name_model,\n","\t\t\tsub_spectrogram_size=sub_spectrogram_size,\n","\t\t\thop_size=hop_size,\n","\t\t\tn_bins=n_bins,\n","\t\t\troot_dir=root_dir,\n","\t\t\ttrain_dir=train_dir,\n","\t\t\tval_dir=val_dir,\n","\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\thop_length=hop_length,\n","\t\t\ttop_db=top_db,\n","\t\t\tf_min=f_min,\n","\t\t\tf_max=f_max,\n","\t\t\tn_fft=n_fft,\n","\t\t\twin_length=win_length,\n","\t\t\tearly_stopping=early_stopping,\n","\t\t\tpatience=patience,\n","\t\t\trepresentation=representation,\n","\t\t\tn_classifiers=n_classifiers,\n","\t\t\tsave_model=save_model\n","\t)\n","\n","\t# Save the model of the last epoch:\n","\tif save_model:\n","\t\tdir = os.path.join(save_dir, f'{name_model}_last_epoch.pt')\n","\t\ttorch.save(model, dir)\n","\n","# Start testing mechanism:\n","if test:\n","\t# Use GPU if available:\n","\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","\t# Empty GPU if available:\n","\tif device == 'cuda':\n","\t\ttorch.cuda.empty_cache()\n","\n","\tuse_cuda = True if device == 'cuda' else False\n","\n","\t# Initialize the model\n","\tmodel = SubSpectralNet(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins, use_cuda=use_cuda)\n","\n","\t# Load the state dictionary\n","\tstate_dict = torch.load(os.path.join(save_dir, model_to_test), map_location=torch.device(device))\n","\n","\t# Apply the state dictionary\n","\tmodel.load_state_dict(state_dict)\n","\n","\t# Move model to GPU if available:\n","\tmodel = model.eval().to(device)\n","\n","\t# Specify keyword arguments for dataloader:\n","\tkwargs = {'num_workers': 8, 'pin_memory': True} if device == 'cuda' else {'num_workers': 8}\n","\n","\t# Specify data transform for the InsectData function:\n","\tdata_transform = transforms.Compose([ToTensor(), ToSubSpectrograms(sub_spectrogram_size=sub_spectrogram_size, hop_size=hop_size, n_bins=n_bins)])\n","\n","\t# Create a test dataframe that contains the paths to the test recordings:\n","\ttest_df = pd.read_csv('......./metadata.csv')\n","\ttest_df = test_df[test_df['subset']=='test']\n","\ttest_df['path'] = test_df['path'].str.replace('data', '/content/drive/MyDrive/Thesis')\n","\n","\t# Create a dictionary for saving the full predictions and the true labels\n","\tprediction_output = {'full_predictions':[], 'true_label':[]}\n","\n","\tfor i in tqdm(range(len(test_df))):\n","\t\tname = ntpath.basename(test_df.iloc[i]['path'][:-4]) # Extracts all basenames of the full files\n","\t\tdata = glob(f'................../baseline 2/test/{name}_*.wav') #Gathers all fragments with the same basename\n","\t\tdf = pd.DataFrame(data, columns=['path']) #create a new temporary df with all fragments of one recording\n","\t\tdf = df['path'].tolist()\n","\n","\t\tpred_ds = InsectDataset(data_dir=df,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\troot_dir= '',\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdefault_labels_path=default_labels_path,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_bins=n_bins,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thop_length=hop_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttop_db=top_db,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_max=f_max,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf_min=f_min,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_fft=n_fft,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twin_length=win_length,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trepresentation=representation,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttransform=data_transform,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taugmentation=False,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfragment=False)\n","\n","\t\ttest_loader = torch.utils.data.DataLoader(pred_ds, batch_size=100, shuffle=False, **kwargs)\n","\n","\t\twith torch.no_grad():\n","\t\t\tfor batch in test_loader:\n","\t\t\t\tpreds = []\n","\t\t\t\tinputs, label = prepare_batch(batch, device=device)\n","\n","\t\t\t\t# Manual normalization:\n","\t\t\t\tinputs_m, inputs_s = inputs.mean(), inputs.std()\n","\t\t\t\tinputs = (inputs - inputs_m) / inputs_s\n","\n","\t\t\t\toutput = model(inputs)\n","\t\t\t\tfor sample in range(len(label)):\n","\t\t\t\t\tpreds.append(output[sample,(n_classifiers-1),:].cpu().numpy())\n","\t\t\t\tpreds_mean = np.mean(preds, axis=0)\n","\t\t\t\tfull_prediction = np.argmax(preds_mean)\n","\t\t\t\tprediction_output['full_predictions'].append(int(full_prediction))\n","\t\t\t\tprediction_output['true_label'].append(int(label[0].item()))\n","\n","\tpredictions = prediction_output['full_predictions']\n","\ttrue_labels = prediction_output['true_label']\n","\n","\tcm = confusion_matrix(true_labels, predictions)\n","\tnp.save(os.path.join(save_dir, f'{name_model}_confusion_matrix_raw.npy'), cm)\n","\n","\treport = classification_report(true_labels, predictions, digits=3, output_dict=True)\n","\tevaluation = pd.DataFrame(report).transpose()\n","\tevaluation.to_csv(os.path.join(save_dir, f'{name_model}_test_evaluation.csv'))\n","\n","\t# Calculate the macro F1 score for direct output:\n","\tmacro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=1)\n","\n","\t# Save the prediction_output to a JSON file:\n","\twith open(os.path.join(save_dir, f'{name_model}_prediction_and_true_label_raw.json'), 'w') as f:\n","\t\tjson.dump(prediction_output, f)\n","\n","\tprint(f'Macro F1 Score: {macro_f1}')\n"]}],"metadata":{"colab":{"collapsed_sections":["qvTlKYFN-M1c","7Q-JvnFR9o2n","lVkKural-Uo3","1nEPHnc1-sTl"],"provenance":[],"authorship_tag":"ABX9TyP6oAtmEmX3SUGHlneKX22Q"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}